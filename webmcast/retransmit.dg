import '/os'
import '/asyncio'

import '/cno'

import 'config'
import 'ebml/ffi'
import 'ebml/lib'
import 'gstreamer'
import 'templates'


on_chunk_cb = (ffi.def_extern error: -1) $ handle data size force ->
    queue = ffi.from_handle handle
    queue :: asyncio.Queue and not force and queue.qsize! >= config.MAX_ENQUEUED_FRAMES =>
        # if the queue overflows, we're already screwed -- the tcp buffer
        # is also full. it will take a while to clear.
        return -1
    queue.put_nowait $ bytes $ ffi.buffer data size
    return 0


Broadcast = subclass object where
    __init__ = self loop ->
        self.cobj = ffi.new 'struct broadcast *'
        self.done = asyncio.Event loop: loop
        lib.broadcast_start self.cobj
        None

    __del__ = self ->
        lib.broadcast_stop self.cobj

    put_nowait = self chunk ->
        # (the method is named this way for api compatibility with asyncio.Queue.)
        lib.broadcast_send self.cobj (ffi.new 'uint8_t[]' chunk) (len chunk)

    connect = async $ self queue skip_headers: False ->
        handle = ffi.new_handle queue
        slot = lib.broadcast_connect self.cobj lib.on_chunk_cb handle skip_headers
        except
            _ =>
                await self.done.wait!
                # not in `finally`. cancelling this coroutine and connecting the queue
                # to another broadcast should be a valid operation.
                queue.close!
            finally => lib.broadcast_disconnect self.cobj slot
        return None

    close = self ->
        self.done.set!


Recoder = subclass object where
    _GLIB_MAIN_LOOP = gstreamer.run_loop!

    __init__ = self rate loop ->
        self._out  = out  = Broadcast loop
        self._pipe = pipe = gstreamer.Pipeline _GLIB_MAIN_LOOP

        self._sink = pipe.make 'appsink'
        self._sink.set_property 'emit-signals' True
        self._sink_handle = self._sink.connect 'new-sample' $ sink ->
            sink.emit 'pull-sample' |>.data |> loop.call_soon_threadsafe out.put_nowait
            return gstreamer.OK

        muxer = pipe.make 'webmmux'
        muxer.set_property 'streamable' True
        muxer.link self._sink

        self._demuxer = pipe.make 'matroskademux'
        self._demuxer_handle = self._demuxer.connect 'pad-added' $ demuxer pad -> if
            pad.name.startswith 'video_' =>
                kind = pad.get_current_caps!.get_structure 0 |>.get_name!
                mux = muxer.request_pad (muxer.get_pad_template 'video_%u') pad.name
                out = pipe.make 'queue'
                out.get_static_pad 'src' |>.link mux
                enc = pipe.make $ if (kind == 'video/x-vp9' => 'vp9enc') (otherwise => 'vp8enc')
                enc.set_property 'keyframe-max-dist' 60
                enc.set_property 'deadline' 1
                enc.set_property 'end-usage' 1  # constant bitrate
                enc.set_property 'target-bitrate' $ rate * 8
                enc.link out
                inp = pipe.make $ if (kind == 'video/x-vp9' => 'vp9dec') (otherwise => 'vp8dec')
                inp.link enc
                pad.link $ inp.get_static_pad 'sink'
            pad.name.startswith 'audio_' =>
                # NOTE gstreamer 1.8 required for opus audio in webmmux
                mux = muxer.request_pad (muxer.get_pad_template 'audio_%u') pad.name
                out = pipe.make 'queue'
                out.get_static_pad 'src' |>.link mux
                pad.link $ out.get_static_pad 'sink'

        self._source = pipe.make 'appsrc'
        self._source.set_property 'max-bytes' 8192
        self._source.link self._demuxer
        pipe.start!
        None

    put_nowait = self chunk ->
        self._source.emit 'push-buffer' $ gstreamer.buffer chunk

    connect = self queue skip_headers: False ->
        self._out.connect queue skip_headers

    close = self ->
        self._source.emit 'end-of-stream'
        self._demuxer.disconnect self._demuxer_handle
        self._sink.disconnect self._sink_handle
        self._out.close!


Source = subclass object where
    __init__ = self loop ->
        self.loop = loop
        self.live = Broadcast loop
        # TODO keep a (bitrate -> transcoded stream) mapping. the transcoded stream
        #      must accept data from this one, feed it through a gstreamer pipeline
        #      or something like that, then broadcast the resulting copy.
        self.smol = Recoder 16000 loop
        self._smt = loop.create_task $ self.live.connect self.smol
        self._upd_rate 0
        None

    _upd_rate = self value: None ->
        self.rate = if value is None => 0.5 * self._rate_pending + 0.5 * self.rate
                       otherwise     => value
        # TODO if bitrate > 2 * (highest available child OR minimum bitrate)
        #      for some ticks, spawn a new child stream connected to this one
        #      via a bitrate-lowering gstreamer pipeline.
        # TODO or maybe do it on demand?..
        # TODO if bitrate < 2 * (highest available child) for some ticks,
        #      destroy the reference to that child. keep it in a weakref dict,
        #      however, in case someone is keeping it alive by watching it and we
        #      decide to restore it later.
        self._rate_pending = 0
        self._rate_updater = self.loop.call_later 1 self._upd_rate

    put_nowait = self chunk ->
        self._rate_pending += len chunk
        self.live.put_nowait chunk

    connect = self queue skip_headers: False ->
        self.live.connect queue skip_headers

    close = self ->
        self._rate_updater.cancel!
        self._rate_updater = None
        self.live.close!  # all recoders will follow


_static_root = next $ iter (import 'static' pure).__path__
_streams     = {}
_collectors  = {}


root = async $ req ->
    req.template = templates.load

    req.path == '/' =>
        req.push 'GET' '/static/css/uikit.min.css' req.accept_headers
        req.push 'GET' '/static/css/layout.css'    req.accept_headers
        req.push 'GET' '/static/js/jquery.min.js'  req.accept_headers
        req.push 'GET' '/static/js/uikit.min.js'   req.accept_headers
        # TODO UI/auth nodes
        return await req.respond_with_error 501 [] 'There is no UI yet.'

    req.path.startswith '/error/' => except
        err =>
            return await req.respond_with_error (int $ req.path !! slice 7 None) [] None
        err :: ValueError =>
            return await req.respond_with_error 400 [] 'Error codes are numbers, silly.'

    req.path.startswith '/static/' =>
        return await req.respond_with_file $ os.path.join _static_root $ req.path !! slice 8 None

    req.path.startswith '/stream/' and req.path.find '/' 8 == -1 =>
        stream_id = req.path !! slice 8 None
        return await $ if
            req.wants_websocket           => signal   req stream_id
            req.method in ('GET', 'HEAD') => download req stream_id
            req.method in ('POST', 'PUT') => upload   req stream_id
            otherwise => req.respond_with_error 405 [('accept', 'GET, POST')] 'Do what now?'

    return await req.respond_with_error 404 [] None


upload = async $ req stream_id ->
    except
        err =>
            stream = _streams !! stream_id
            except
                err =>
                    _collectors.pop stream |>.cancel!
                err :: KeyError =>
                    return await req.respond_with_error 403 [] 'Stream ID already taken.'
        err :: KeyError =>
            stream = _streams !! stream_id = Source req.conn.loop
    except
        _ =>
            while chunk = await req.payload.read 16384 =>
                stream.put_nowait chunk =>
                    return await req.respond_with_error 400 [] 'Malformed EBML.'
            return await req.respond 204 [] b''
        finally =>
            _collectors !! stream = req.conn.loop.create_task
                where
                    await asyncio.sleep config.MAX_DOWNTIME loop: req.conn.loop
                    _collectors !!~ stream
                    _streams !!~ stream_id
                    stream.close!


download = async $ req stream_id ->
    stream = except
        err => _streams !! stream_id
        err :: KeyError => return await req.respond_with_error 404 [] None

    # force excess frames to stay in the queue instead of the transport's buffer
    # XXX may interact badly with HTTP 2 since these limits are connection-wide.
    # XXX the tcp buffer is huge anyway. that's where the delay is. sctp anyone?
    req.conn.transport.set_write_buffer_limits 512 256
    queue = cno.Channel loop: req.conn.loop
    writer = req.conn.loop.create_task $ stream.connect queue
    stream = None  # make sure reference loops do not touch the stream
    except
        _ => return await req.respond 200
            list'
                'content-type', 'video/webm'
                'cache-control', 'no-cache'
            queue
        finally => writer.cancel!


signal = async $ req stream_id ->
    stream = except
        err => _streams !! stream_id
        err :: KeyError => return await req.respond_with_error 404 [] None

    with io = await req.websocket! =>
        # TODO signaled mode (see README)
        return io.close 1003 'signaled mode not implemented'
