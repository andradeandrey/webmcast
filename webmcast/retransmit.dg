import '/os'
import '/asyncio'
import '/weakref'

import '/cno'

import 'config'
import 'static'
import 'templates'
import 'ebml/ffi'
import 'ebml/lib'


on_chunk_cb = (ffi.def_extern error: -1) $ handle data size force ->
    queue = ffi.from_handle handle
    queue :: Stream =>
        # this may look like a pointless copy now, but wait until you see
        # how much more copies will be created anyway...
        return queue.send $ bytes $ ffi.buffer data size
    not force and queue.qsize! >= config.MAX_ENQUEUED_FRAMES =>
        # if the queue overflows, we're already screwed -- the tcp buffer
        # is also full. it will take a while to clear.
        return -1
    queue.put_nowait $ bytes $ ffi.buffer data size
    return 0


Stream = subclass object where
    __init__ = self loop ->
        self.loop = loop
        self.cffi = ffi.new 'struct broadcast *'
        self.done = asyncio.Event loop: loop
        self._upd_rate 0
        lib.broadcast_start self.cffi
        # TODO keep a (bitrate -> transcoded stream) mapping. the transcoded stream
        #      must accept data from this one, feed it through a gstreamer pipeline
        #      or something like that, then broadcast the resulting copy.
        None

    _upd_rate = self value: None ->
        self.rate = if value is None => 0.5 * self._rate_pending + 0.5 * self.rate
                       otherwise     => value
        # TODO if bitrate > 2 * (highest available child OR minimum bitrate)
        #      for some ticks, spawn a new child stream connected to this one
        #      via a bitrate-lowering gstreamer pipeline.
        # TODO or maybe do it on demand?..
        # TODO if bitrate < 2 * (highest available child) for some ticks,
        #      destroy the reference to that child. keep it in a weakref dict,
        #      however, in case someone is keeping it alive by watching it and we
        #      decide to restore it later.
        self._rate_pending = 0
        self._rate_updater = self.loop.call_later 1 self._upd_rate

    __del__ = self ->
        lib.broadcast_stop self.cffi
        self._rate_updater.cancel!

    send = self chunk ->
        self._rate_pending += len chunk
        lib.broadcast_send self.cffi (ffi.new 'uint8_t[]' chunk) (len chunk)

    attach = async $ self queue skip_headers: False ->
        handle = ffi.new_handle queue
        slot = lib.broadcast_connect self.cffi lib.on_chunk_cb handle skip_headers
        except
            _ =>
                await self.done.wait!
                queue.close!
            finally =>
                lib.broadcast_disconnect self.cffi slot

    close = self ->
        # TODO destroy all transcoded streams.
        self.done.set!

    close_later = async $ self timeout loop: None ->
        # can't just use `loop.call_later(timeout, self.close)` because that handle would
        # keep this object alive until destroyed explicitly. a finished task does not.
        await asyncio.sleep timeout loop: loop
        self.close!


static_root = next $ iter static.__path__
streams = weakref.WeakValueDictionary!
collectors = weakref.WeakKeyDictionary!


root = async $ req ->
    req.template = templates.load

    req.path == '/' =>
        req.push 'GET' '/static/css/uikit.min.css' req.accept_headers
        req.push 'GET' '/static/css/layout.css'    req.accept_headers
        req.push 'GET' '/static/js/jquery.min.js'  req.accept_headers
        req.push 'GET' '/static/js/uikit.min.js'   req.accept_headers
        # TODO UI/auth nodes
        return await req.respond_with_error 501 [] 'There is no UI yet.'

    req.path.startswith '/error/' => except
        err => code = int $ req.path !! slice 7 None
        err :: ValueError =>
            return await req.respond_with_error 400 [] 'Error codes are numbers, silly.'
        err is None =>
            return await req.respond_with_error code [] None

    req.path.startswith '/static/' =>
        return await req.respond_with_file $ os.path.join static_root $ req.path !! slice 8 None

    req.path.startswith '/stream/' and req.path.find '/' 8 == -1 =>
        stream_id = req.path !! slice 8 None

        req.method in ('POST', 'PUT') =>
            # TODO auth tokens
            except
                err =>
                    stream = streams !! stream_id
                    except
                        err =>
                            collectors.pop stream |>.cancel!
                        err :: KeyError =>
                            return await req.respond_with_error 403 [] 'Stream ID already taken.'
                err :: KeyError =>
                    stream = streams !! stream_id = Stream req.conn.loop
            except
                err =>
                    while chunk = await req.payload.read 16384 =>
                        stream.send chunk =>
                            return await req.respond_with_error 400 [] 'Malformed EBML.'
                    return await req.respond 204 [] b''
                finally =>
                    collectors !! stream = req.conn.loop.create_task $
                        stream.close_later config.MAX_DOWNTIME req.conn.loop

        stream = except
            err => streams !! stream_id
            err :: KeyError => return await req.respond_with_error 404 [] None

        not $ req.method in ('GET', 'HEAD') =>
            return await req.respond_with_error 405 [] 'Streams can only be GET or POSTed.'

        (req.header_map.get 'upgrade' '').lower! == 'websocket' =>
            with io = await req.websocket! =>
                # TODO signaled mode (see README)
                return io.close 1003 'signaled mode not implemented'

        queue = cno.Channel loop: req.conn.loop
        writer = req.conn.loop.create_task $ stream.attach queue
        # force excess frames to stay in the queue instead of the transport's buffer
        # XXX may interact badly with HTTP 2 since these limits are connection-wide.
        # XXX the tcp buffer is huge anyway. that's where the delay is. sctp anyone?
        req.conn.transport.set_write_buffer_limits 512 256
        except
            err =>
                return await req.respond 200
                    list'
                        'content-type', 'video/webm'
                        'cache-control', 'no-cache'
                    queue
            finally =>
                writer.cancel!

    return await req.respond_with_error 404 [] None
